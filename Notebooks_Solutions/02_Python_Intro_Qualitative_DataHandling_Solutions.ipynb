{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48eca60f-5bb9-49b3-aebd-30cffd9d99cb",
   "metadata": {},
   "source": [
    "<img src=\"../Images/DSC_Logo.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f387c-9f50-4373-9f5a-b2ef0a1c2089",
   "metadata": {},
   "source": [
    "# Data Handling in Python\n",
    "\n",
    "This notebook introduces fundamental data handling techniques in Python, with a focus on working with qualitative data. It covers how to import data from external files and write data back to files, and how to use Python libraries for data handling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7475f-703b-4fde-8045-b43e5eefbd13",
   "metadata": {},
   "source": [
    "## 1. Reading and Writing Text Files\n",
    "\n",
    "Up until now, we’ve worked only with data created inside our own code. But in real-world projects, you’ll mainly work with existing data and files. Let's see how to open and read text files, as well as how to save (write) new files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493bdbb-cd8e-4ff6-a175-0030bddfae9c",
   "metadata": {},
   "source": [
    "We can use the `with` operator **to open a text file**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a77a0-1ae0-435d-99af-403b191d19dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open the file \"Interview1.txt\" (from a relative path) in read mode (\"r\"):\n",
    "with open(\"../Data/Interviews_ClimateChange/Interview1.txt\", \"r\") as f: \n",
    "    data = f.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b035f66-f0b4-4386-8b60-f566d2ca909a",
   "metadata": {},
   "source": [
    "This reads the contents of .txt file and stores it in the variable \"data\".\n",
    "\n",
    "**To save text** into a new file, we use almost the same structure, but change the mode to \"w\" (write):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06d0fd-6139-4489-8a64-7175af276916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_string = \"This is a new interview.\"\n",
    "\n",
    "# Save the file \"Interview4.txt\" (to a relative path) in write mode (\"w\"):\n",
    "with open(\"../Data/Interviews_ClimateChange/Interview4.txt\", \"w\") as f:\n",
    "    f.write(new_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d37421-69e2-422f-a9ce-0ee3b4b4fcfa",
   "metadata": {},
   "source": [
    "Now, a file called Interview4.txt will be created (or overwritten) with the text from \"new_string\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4332fa5-6e12-46f9-8844-d0b4e1f0f11b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2 Using Libraries for Data Handling\n",
    "\n",
    "In this section, we introduce a few Python libraries that are useful for basic work with qualitative data. These libraries help with importing, editing, and organizing data for analysis, especially when dealing with formats like text or structured files (e.g. JSON, CSV). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42647aab-fb97-4984-9c32-f73fe052c86f",
   "metadata": {},
   "source": [
    "## 2.1 `json`\n",
    "\n",
    "The `json` library helps you work with **nested (hierarchical) data** - data that contains lists, dictionaries, or other structures inside it. JSON stands for JavaScript Object Notation. It’s a common way to store and send data on the web. You’ll see it used a lot when working with **websites and APIs**.\n",
    "\n",
    "Let’s **load** a few entries from a real-world dataset of HuffPost news articles that contains thousands of news headlines from 2012 to 2022, where each line is a separate article in JSON format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e3709-b6cb-46d1-9234-56d09a1294ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the json library (part of Python’s standard library)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5946d-6183-45e9-8359-4efb9575ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset file (relative path from current notebook)\n",
    "file_path = \"../Data/sample_articles_10000.json\"\n",
    "\n",
    "# Create an empty list to store the loaded articles\n",
    "news_articles = []\n",
    "\n",
    "# Open the file in read mode (\"r\")\n",
    "with open(file_path, \"r\") as f:\n",
    "    # Loop over each line in the file (each line is a separate news article in JSON format)\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5:  # Stop after reading the first 5 articles (just for demonstration)\n",
    "            break\n",
    "        # Convert the JSON string (one line) into a Python dictionary and add it to the list\n",
    "        news_articles.append(json.loads(line))\n",
    "\n",
    "# Loop through the loaded articles and print selected fields\n",
    "for article in news_articles:\n",
    "    # Access and print the author's name, category, and headline using dictionary keys\n",
    "    print(f\"{article['authors']} ({article['category']}): {article['headline']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6e87c-16d7-4586-ad3b-309ac9b8ff51",
   "metadata": {},
   "source": [
    "This is how we can **write** a JSON-style data structure from scratch in Python: We define a dictionary to represent a single news article, including keys like \"link\", \"headline\", \"category\", \"authors\", and \"date\". If we have multiple articles, we can store them in a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1dc057-356e-48db-bcf9-f2676e4d81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles = [\n",
    "    {\n",
    "        \"link\": \"https://www.huffpost.com/entry/covid-boosters-uptake-us_n_632d719ee4b087fae6feaac9\",\n",
    "        \"headline\": \"Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\",\n",
    "        \"category\": \"U.S. NEWS\",\n",
    "        \"short_description\": \"Health experts said it is too early to predict whether demand would match up...\",\n",
    "        \"authors\": \"Carla K. Johnson, AP\",\n",
    "        \"date\": \"2022-09-23\"\n",
    "    },\n",
    "    # more articles could go here\n",
    "]\n",
    "\n",
    "for article in news_articles:\n",
    "    print(f\"{article['authors']} ({article['category']}): {article['headline']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d36e390-002b-40a5-9c1d-62e228fdcba6",
   "metadata": {},
   "source": [
    "Here is how we can **load** only the headlines and **write** them to a single text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4cd621-4aee-4b22-890d-1f75b69fda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../Data/sample_articles_10000.json\"\n",
    "output_path = \"../Data/all_headlines.txt\"\n",
    "\n",
    "# Open the dataset and extract headlines\n",
    "headlines = []\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        article = json.loads(line)\n",
    "        headline = article.get(\"headline\", \"\").strip()\n",
    "        if headline:\n",
    "            headlines.append(headline)\n",
    "\n",
    "# Write all headlines to a single text file, one per line\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for headline in headlines:\n",
    "        f_out.write(headline + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54541fe1-2555-4665-a907-8cc84f1e2877",
   "metadata": {},
   "source": [
    "## 2.2 `glob`\n",
    "\n",
    "Suppose you have a folder with multiple .txt files - each one is a transcript of a different interview. You want to automatically load all these files to analyze them in Python. The `glob` library allows you to search for files in a folder based on patterns. In this example, we’ll load all .txt files from a folder and print their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8136a8-ef5d-459b-9339-566da5eb153d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the glob library (part of Python’s standard library)\n",
    "import glob\n",
    "\n",
    "# Get all text files in the \"Interviews_ClimateChange\" folder\n",
    "files = glob.glob(\"../Data/Interviews_ClimateChange/*.txt\")\n",
    "\n",
    "# Read and display contents of each file\n",
    "for filepath in files:\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "        print(f\"--- Contents of {filepath} ---\")\n",
    "        print(content)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0f1c4-3008-4e13-8674-405ac9f4c485",
   "metadata": {},
   "source": [
    "## 2.3 `beautifulsoup4` & `requests`\n",
    "\n",
    "`beautifulsoup4` is a library used to parse HTML (HyperText Markup Language) and extract information. It’s perfect for getting data from websites in a structured, readable way. Together with `requests` we can conduct our first web scraping task. Let`s scrape some text from a Wikipedia page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e617b0f2-cc19-4f57-803b-b63b31602c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install & import the libraries\n",
    "!pip install beautifulsoup4 \n",
    "!pip install requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdfe9b4-86bd-47ec-8b86-5f79f4715f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL of the Wikipedia page you want to fetch\n",
    "url = \"https://en.wikipedia.org/wiki/Democracy\"\n",
    "\n",
    "# Send an HTTP GET request to the URL and store the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using BeautifulSoup\n",
    "# \"html.parser\" tells BeautifulSoup to interpret the content as standard HTML\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the main content section of the Wikipedia article\n",
    "# Wikipedia stores article content inside a <div> tag with the ID \"mw-content-text\"\n",
    "body = soup.find(\"div\", {\"id\": \"mw-content-text\"})\n",
    "\n",
    "# Find all <p> tags (paragraphs) within that section and extract their text\n",
    "# Only include paragraphs that are not empty\n",
    "paragraphs = [p.text for p in body.find_all(\"p\") if p.text.strip()]\n",
    "\n",
    "# Join all the paragraphs into one large text block\n",
    "main_text = \" \".join(paragraphs) # \" \".join(): joins a list of strings into one single string, with a space (\" \") placed between each element\n",
    "\n",
    "# Print the first 500 characters of the article body\n",
    "print(main_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937888c3-d62e-485e-951a-2a3d6edbaa94",
   "metadata": {},
   "source": [
    "## 2.4 `pandas`\n",
    "\n",
    "`pandas` is the most widely used Python library for working with tabular data - data arranged in rows and columns - commonly found in files like .csv or Excel spreadsheets. \n",
    "\n",
    "`pandas` makes it easy to read files like `.csv` into `DataFrames`, which keep both the data and its structure intact. This allows you to efficiently explore, organize, and analyze data within your code. `DataFrames` are similar to Excel spreadsheets or database tables. They have a 2-dimensional data structure and labeled axes (rows and columns). These are indexed for efficient data retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d26e147-3254-4530-8dd1-9458c9ba8fb3",
   "metadata": {},
   "source": [
    "<img src=\"../Images/dataframe.png\" style=\"width: 300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20a8e6-72eb-42f9-a609-facdbea9bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install & import pandas\n",
    "!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffea9d3-ee4f-47c7-8cf8-afda005d6e17",
   "metadata": {},
   "source": [
    "Let's look at some basic commands with `pandas`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c73ffc-1eed-46d4-ae73-0f4d69a8ef94",
   "metadata": {},
   "source": [
    "- To **create a DataFrame** from a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3300775-26e4-4ada-b94c-0081cdf17c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {\"names\": [\"Alice\", \"Mary\", \"Kim\", \"Deniz\", \"Carla\", \"Linus\"]}\n",
    "df = pd.DataFrame(names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad6a9b-f362-499d-86dc-f4bfcefb3f40",
   "metadata": {},
   "source": [
    "Simply type `df` or use `print(df)` to display the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ca57b-1eac-45fb-b98d-2361f7049f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98173cdc-54ba-44ff-bec9-e614d995fe6f",
   "metadata": {},
   "source": [
    "- **Saving** a DataFrame to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaec591-eb47-4adc-b81d-6b81fa6d7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee62ccc-9d81-4341-8797-6e722bd8b60f",
   "metadata": {},
   "source": [
    "Setting `index=False` prevents pandas from writing row indices to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b900b6-d8ec-4094-af8d-a9de290b5201",
   "metadata": {},
   "source": [
    "- **Reading** a DataFrame from CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2c8a8-ae6c-40c1-bc6f-f3b2e5da824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic = pd.read_csv(\"../Data/Titanic-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1235d47f-2bcb-4536-ab0f-7ccf19b800a8",
   "metadata": {},
   "source": [
    "- **Quick inspection** - getting to know the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89baa29-09d7-423f-a8f5-4ea9d22be430",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic.head() # Preview (default: 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5b022-0050-4380-9255-4716af75ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic.head(10) # Preview 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a23f64-4fb2-49a0-971d-d3f661bd9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titanic.describe() # Summarize the statistical properties of numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48549039-660b-4aa2-966d-3122a4d7d0a5",
   "metadata": {},
   "source": [
    "- **Adding new column** to a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba1924-7180-49ae-aeef-fe031c6b6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ages\"] = [20, 26, 20, 18, 52, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb0779c-d425-46d9-ae5c-2008c50a157a",
   "metadata": {},
   "source": [
    "Ensure the new column has the same number of entries as existing rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e674b74-6604-4e38-9dfc-347ecbcc5061",
   "metadata": {},
   "source": [
    "- **Accessing** a specific **column**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503185f-bd4a-4931-8408-fa21c049d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = df[\"ages\"]\n",
    "# or:\n",
    "ages = df.ages\n",
    "print(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f610d9e-e39c-4724-a281-f3f8d1c405d4",
   "metadata": {},
   "source": [
    "- **Converting** a column to a **list**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14d7b0-36fd-4255-a8a0-ab10a2dae4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ages\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a6bec-c84b-421f-acf0-3c87bd18e4d3",
   "metadata": {},
   "source": [
    "- Isolating **unique values** in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f946df7-7f0d-441c-8b25-4828e90e6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ages\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb5f15-b89f-483e-8741-2d1925bc8794",
   "metadata": {},
   "source": [
    "- **Accessing** a specific **row** with iloc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ffd07-bbb5-41a2-9670-5158e19cf581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972061ed-f45e-45e3-aaba-b65ea7092454",
   "metadata": {},
   "source": [
    "- **Sort by** one or more columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c2397-0b9e-4170-ba4b-d6dcf121b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"ages\", ascending=False) # ascending=False tells pandas to sort values from highest to lowest instead of the default (lowest to highest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f0a7df-0b93-4992-979f-4e14fb414a22",
   "metadata": {},
   "source": [
    "- **Reset index**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cec290-3b3f-4733-afd2-9c01bb4f0ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e962c1-6254-4298-91b8-8f53c2ad639a",
   "metadata": {},
   "source": [
    "### **Exercise 1:** \n",
    "\n",
    "Load the World Happiness Report 2024 from `../Data/World-happiness-report-2024.csv` using `pandas`. Sort the data table by \"Ladder score\" and print the top 5 countries with the highest \"Ladder score\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1c058-ce3e-4e33-a1c6-334292434bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df2 = pd.read_csv(\"../Data/World-happiness-report-2024.csv\")\n",
    "\n",
    "# Sort df\n",
    "df2.sort_values(\"Ladder score\", ascending=False)\n",
    "\n",
    "# Print top 5 happiest countries (top 10 rows)\n",
    "df2[[\"Country name\", \"Ladder score\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac02244-211f-4836-94ea-1f6ad2386523",
   "metadata": {},
   "source": [
    "- **Iterating** over a DataFrame with `iterrows()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f246b2af-b7dc-4b46-b735-be85da4e1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    print(row[\"names\"], row[\"ages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f031c-8e39-449f-8c7b-16884eab03e9",
   "metadata": {},
   "source": [
    "- **Select rows** by conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ccb21e-d8c5-47ac-9adf-9896cca67c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"ages\"] <= 40]\n",
    "# or:\n",
    "df.query(\"ages > 30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacdbaf-2257-45af-acb3-fdc99e6a30e8",
   "metadata": {},
   "source": [
    "Add more filters by chaining conditions with `&` (and) or `|` (or)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252a207-f92e-4c80-a7cf-361a3b38d9c8",
   "metadata": {},
   "source": [
    "- **Cleaning** the DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ff37c6-a8e5-4b9b-aecc-3c5b75fa9fce",
   "metadata": {},
   "source": [
    "Remove column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b0ec0-9316-4fe9-9b41-0801a3a2f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"ages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18131b8d-af46-47d2-9cce-390d7457a100",
   "metadata": {},
   "source": [
    "Keep only a certain column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3882bf-a75a-4518-83d0-c36e84a8353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"names\"]]\n",
    "# or\n",
    "df.filter([\"names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e5a928-93d4-462d-9b9a-e48755efb0a6",
   "metadata": {},
   "source": [
    "- Column **name pattern filtering**, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca27e2d-d9f7-4d4d-aa84-9d8024e7a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(regex=\"^a\")  # selects all columns starting with \"a\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440061c8-3f3b-4284-9af1-7bc704ab1a95",
   "metadata": {},
   "source": [
    "- Remove rows with **missing values**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18b709a-45e1-4c60-af82-941dd3d8b400",
   "metadata": {},
   "source": [
    "From a specific column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7548f-61fe-471b-9c40-3d464533314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"ages\"].notna()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba47354-be33-443c-8682-20b24ab4eb3a",
   "metadata": {},
   "source": [
    "Where all columns are empty (default: \"any\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171a594-6195-4152-88ac-943c74b4a2a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aec228-bbd0-4ea9-99f9-9bda2f459163",
   "metadata": {},
   "source": [
    "- **Convert data type** id needed (e.g. float to int):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44266e6-5537-4d65-895d-5488ac48f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ages\"] = df[\"ages\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b3ce-3d70-49d1-9654-8773f7ac400c",
   "metadata": {},
   "source": [
    "- **Searching text data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b596e5-6e69-4a93-aada-a3cc58de94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"names\"].str.contains(\"A\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a0fee-4f6d-41c4-ba30-44bfa60ad708",
   "metadata": {},
   "source": [
    "-  **Grouping Data by** one or more columns for aggregate analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1224702-38eb-478d-b0ad-0a889af56a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"ages\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223385fe-d4b8-4596-86f2-ef36c0281a24",
   "metadata": {},
   "source": [
    "Chain with `.sum()`, `.mean()`, `.count()` etc., for numeric summaries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
